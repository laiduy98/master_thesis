\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}

This document comprises two distinct segments, starting with an apprenticeship report followed by an in-depth explanation of the master's thesis about the last mission in the list below.

In the initial section, an overview is presented of my work as an apprentice within the company. A brief introduction of the organization is provided, followed by a report of the mission that I have undertaken:

\begin{itemize}
    \item Enhancing Fake and Near-Duplicate Fiber Distribution Point Images Detection.

Investigating and refining methods to recognize counterfeit and near-duplicated fiber distribution point images, avoiding paying for forgery work.

    \item Exploring Feasibility of Migrating Infrastructure to Google Cloud

Evaluating the viability of transferring the existing infrastructure to Google Cloud, harnessing cloud capabilities for improved scalability, efficiency, and innovation.

    \item Categorizing Customer Conversations from SFR call center data via NLP Techniques.

Employing Natural Language Processing techniques to categorize and extract insights from customer interactions, thereby enhancing service quality and decision-making.

\end{itemize}

Customer satisfaction is one of the most important factors of any company in the market nowadays. The collection of valued data from the conversations with the customer from the call center and extracting the meaning out of it has been done by almost every enterprise to improve competitive advantage in the market with other competitors. In the second segment, This article dives into more detail about the analysis of transcribed calls document of SFR's client, with the desire to find out the topics of the conversation, thereby helping the company to improve customer satisfaction later on. To do so, I will apply a French language model named CamemBERT, a variety of RoBERTa to extract the sentence meaning in a form of a vector in the vector space, and then apply some clustering techniques to cluster conversations into topics. We will find the most important words by using TF-IDF, or define the topic by a representative document that is closest to the centroids.

\textbf{Keywords}: Computer vision, CLIP, Vertex AI, Google Cloud, CamemBERT, Language model, Topic clustering, TF-IDF
